{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a940a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"code_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb7bf320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.560180</td>\n",
       "      <td>0.397133</td>\n",
       "      <td>-0.067608</td>\n",
       "      <td>-1.361568</td>\n",
       "      <td>-1.189112</td>\n",
       "      <td>0.362005</td>\n",
       "      <td>-2.113351</td>\n",
       "      <td>-0.945830</td>\n",
       "      <td>0.967215</td>\n",
       "      <td>-1.035563</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.982848</td>\n",
       "      <td>-2.182985</td>\n",
       "      <td>-1.788343</td>\n",
       "      <td>-1.500597</td>\n",
       "      <td>0.575761</td>\n",
       "      <td>-1.418272</td>\n",
       "      <td>1.969096</td>\n",
       "      <td>-1.663663</td>\n",
       "      <td>0.929276</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.617345</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.107997</td>\n",
       "      <td>-1.275459</td>\n",
       "      <td>-1.116872</td>\n",
       "      <td>0.391739</td>\n",
       "      <td>-2.048924</td>\n",
       "      <td>-1.050489</td>\n",
       "      <td>0.850765</td>\n",
       "      <td>-1.035608</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.709290</td>\n",
       "      <td>-2.184924</td>\n",
       "      <td>-1.784352</td>\n",
       "      <td>-1.194703</td>\n",
       "      <td>0.194767</td>\n",
       "      <td>-1.383189</td>\n",
       "      <td>2.073854</td>\n",
       "      <td>-1.415486</td>\n",
       "      <td>0.632933</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.597761</td>\n",
       "      <td>0.410195</td>\n",
       "      <td>-0.095720</td>\n",
       "      <td>-1.338432</td>\n",
       "      <td>-1.206770</td>\n",
       "      <td>0.355120</td>\n",
       "      <td>-2.098167</td>\n",
       "      <td>-0.965952</td>\n",
       "      <td>0.973628</td>\n",
       "      <td>-1.008978</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.004396</td>\n",
       "      <td>-2.188181</td>\n",
       "      <td>-1.790508</td>\n",
       "      <td>-1.496068</td>\n",
       "      <td>0.613387</td>\n",
       "      <td>-1.429072</td>\n",
       "      <td>1.965157</td>\n",
       "      <td>-1.676064</td>\n",
       "      <td>0.918330</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.546645</td>\n",
       "      <td>0.208720</td>\n",
       "      <td>-0.045373</td>\n",
       "      <td>-1.222537</td>\n",
       "      <td>-1.078728</td>\n",
       "      <td>0.421885</td>\n",
       "      <td>-2.104985</td>\n",
       "      <td>-1.122851</td>\n",
       "      <td>0.968126</td>\n",
       "      <td>-0.895802</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.837438</td>\n",
       "      <td>-2.176035</td>\n",
       "      <td>-1.723567</td>\n",
       "      <td>-1.477411</td>\n",
       "      <td>0.382508</td>\n",
       "      <td>-1.410528</td>\n",
       "      <td>1.997823</td>\n",
       "      <td>-1.583785</td>\n",
       "      <td>0.787734</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.643125</td>\n",
       "      <td>0.430050</td>\n",
       "      <td>-0.008826</td>\n",
       "      <td>-1.351897</td>\n",
       "      <td>-1.171904</td>\n",
       "      <td>0.367173</td>\n",
       "      <td>-2.125630</td>\n",
       "      <td>-0.877730</td>\n",
       "      <td>0.865652</td>\n",
       "      <td>-1.048714</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.947140</td>\n",
       "      <td>-2.250539</td>\n",
       "      <td>-1.726540</td>\n",
       "      <td>-1.531785</td>\n",
       "      <td>0.549569</td>\n",
       "      <td>-1.434322</td>\n",
       "      <td>2.015190</td>\n",
       "      <td>-1.620357</td>\n",
       "      <td>1.025025</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>-1.765830</td>\n",
       "      <td>-2.682315</td>\n",
       "      <td>-1.481811</td>\n",
       "      <td>1.248640</td>\n",
       "      <td>-0.725905</td>\n",
       "      <td>1.540399</td>\n",
       "      <td>-0.321199</td>\n",
       "      <td>-0.397931</td>\n",
       "      <td>-0.888173</td>\n",
       "      <td>0.497768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.909174</td>\n",
       "      <td>0.503568</td>\n",
       "      <td>-0.641167</td>\n",
       "      <td>-1.294205</td>\n",
       "      <td>-2.402035</td>\n",
       "      <td>-1.718075</td>\n",
       "      <td>-0.915480</td>\n",
       "      <td>-2.096138</td>\n",
       "      <td>0.412238</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>-1.898498</td>\n",
       "      <td>-1.897484</td>\n",
       "      <td>-1.761415</td>\n",
       "      <td>0.662543</td>\n",
       "      <td>-0.868898</td>\n",
       "      <td>1.392034</td>\n",
       "      <td>-0.985371</td>\n",
       "      <td>-0.187743</td>\n",
       "      <td>-0.496623</td>\n",
       "      <td>0.845496</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.382139</td>\n",
       "      <td>0.097382</td>\n",
       "      <td>-1.010758</td>\n",
       "      <td>-1.461787</td>\n",
       "      <td>-1.710525</td>\n",
       "      <td>-1.110383</td>\n",
       "      <td>-0.824634</td>\n",
       "      <td>-1.276787</td>\n",
       "      <td>0.273552</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>-1.931803</td>\n",
       "      <td>-4.522925</td>\n",
       "      <td>0.445944</td>\n",
       "      <td>0.603920</td>\n",
       "      <td>1.469562</td>\n",
       "      <td>-4.925057</td>\n",
       "      <td>-0.936538</td>\n",
       "      <td>-0.120320</td>\n",
       "      <td>0.228790</td>\n",
       "      <td>-2.796853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972262</td>\n",
       "      <td>-0.030479</td>\n",
       "      <td>0.135137</td>\n",
       "      <td>1.463492</td>\n",
       "      <td>-1.170290</td>\n",
       "      <td>0.936117</td>\n",
       "      <td>-1.204324</td>\n",
       "      <td>1.097006</td>\n",
       "      <td>-0.862900</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>-1.669846</td>\n",
       "      <td>-2.186171</td>\n",
       "      <td>-2.102323</td>\n",
       "      <td>0.619586</td>\n",
       "      <td>-0.960931</td>\n",
       "      <td>1.629884</td>\n",
       "      <td>-0.794663</td>\n",
       "      <td>-0.106962</td>\n",
       "      <td>-0.479505</td>\n",
       "      <td>0.925149</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.258445</td>\n",
       "      <td>0.197480</td>\n",
       "      <td>-0.972337</td>\n",
       "      <td>-1.168023</td>\n",
       "      <td>-1.738411</td>\n",
       "      <td>-1.155843</td>\n",
       "      <td>-0.791999</td>\n",
       "      <td>-1.303357</td>\n",
       "      <td>0.551702</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>-1.454368</td>\n",
       "      <td>-2.128856</td>\n",
       "      <td>-2.655107</td>\n",
       "      <td>0.825272</td>\n",
       "      <td>0.783060</td>\n",
       "      <td>1.926405</td>\n",
       "      <td>0.531026</td>\n",
       "      <td>-1.259165</td>\n",
       "      <td>-2.362457</td>\n",
       "      <td>-0.169858</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.243582</td>\n",
       "      <td>0.487808</td>\n",
       "      <td>-0.567364</td>\n",
       "      <td>-0.414606</td>\n",
       "      <td>-1.599639</td>\n",
       "      <td>-2.484789</td>\n",
       "      <td>-0.840587</td>\n",
       "      <td>-2.084066</td>\n",
       "      <td>-0.754227</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.560180  0.397133 -0.067608 -1.361568 -1.189112  0.362005 -2.113351   \n",
       "1    -0.617345  0.004933  0.107997 -1.275459 -1.116872  0.391739 -2.048924   \n",
       "2    -0.597761  0.410195 -0.095720 -1.338432 -1.206770  0.355120 -2.098167   \n",
       "3    -0.546645  0.208720 -0.045373 -1.222537 -1.078728  0.421885 -2.104985   \n",
       "4    -0.643125  0.430050 -0.008826 -1.351897 -1.171904  0.367173 -2.125630   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1171 -1.765830 -2.682315 -1.481811  1.248640 -0.725905  1.540399 -0.321199   \n",
       "1172 -1.898498 -1.897484 -1.761415  0.662543 -0.868898  1.392034 -0.985371   \n",
       "1173 -1.931803 -4.522925  0.445944  0.603920  1.469562 -4.925057 -0.936538   \n",
       "1174 -1.669846 -2.186171 -2.102323  0.619586 -0.960931  1.629884 -0.794663   \n",
       "1175 -1.454368 -2.128856 -2.655107  0.825272  0.783060  1.926405  0.531026   \n",
       "\n",
       "             7         8         9  ...       759       760       761  \\\n",
       "0    -0.945830  0.967215 -1.035563  ... -1.982848 -2.182985 -1.788343   \n",
       "1    -1.050489  0.850765 -1.035608  ... -1.709290 -2.184924 -1.784352   \n",
       "2    -0.965952  0.973628 -1.008978  ... -2.004396 -2.188181 -1.790508   \n",
       "3    -1.122851  0.968126 -0.895802  ... -1.837438 -2.176035 -1.723567   \n",
       "4    -0.877730  0.865652 -1.048714  ... -1.947140 -2.250539 -1.726540   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1171 -0.397931 -0.888173  0.497768  ... -0.909174  0.503568 -0.641167   \n",
       "1172 -0.187743 -0.496623  0.845496  ... -1.382139  0.097382 -1.010758   \n",
       "1173 -0.120320  0.228790 -2.796853  ...  0.972262 -0.030479  0.135137   \n",
       "1174 -0.106962 -0.479505  0.925149  ... -1.258445  0.197480 -0.972337   \n",
       "1175 -1.259165 -2.362457 -0.169858  ... -1.243582  0.487808 -0.567364   \n",
       "\n",
       "           762       763       764       765       766       767  score  \n",
       "0    -1.500597  0.575761 -1.418272  1.969096 -1.663663  0.929276   10.0  \n",
       "1    -1.194703  0.194767 -1.383189  2.073854 -1.415486  0.632933    8.0  \n",
       "2    -1.496068  0.613387 -1.429072  1.965157 -1.676064  0.918330    7.0  \n",
       "3    -1.477411  0.382508 -1.410528  1.997823 -1.583785  0.787734    5.0  \n",
       "4    -1.531785  0.549569 -1.434322  2.015190 -1.620357  1.025025    6.0  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "1171 -1.294205 -2.402035 -1.718075 -0.915480 -2.096138  0.412238    1.0  \n",
       "1172 -1.461787 -1.710525 -1.110383 -0.824634 -1.276787  0.273552    8.0  \n",
       "1173  1.463492 -1.170290  0.936117 -1.204324  1.097006 -0.862900    2.0  \n",
       "1174 -1.168023 -1.738411 -1.155843 -0.791999 -1.303357  0.551702    8.0  \n",
       "1175 -0.414606 -1.599639 -2.484789 -0.840587 -2.084066 -0.754227   10.0  \n",
       "\n",
       "[1176 rows x 769 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15a5364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace(88,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd3d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace(6.5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f55aa7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "# ploting scatterplot to show the relationship between any two features\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot using seaborn\n",
    "sns.scatterplot(x= 759, y='score', data=df)\n",
    "\n",
    "# Setting title and labels\n",
    "plt.title('Scatter plot of 759  vs. score')\n",
    "plt.xlabel('Feature 759')\n",
    "plt.ylabel('Feature score')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e8bf78e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['score'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3276\\1303324590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Fit the model to the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindependent_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdependent_variable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Predict the values using the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    663\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    770\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['score'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "independent_variable = np.array(['score']) \n",
    "dependent_variable = np.array(['759']) \n",
    "\n",
    "# Reshape the independent variable to a 2D array if it's a single feature\n",
    "independent_variable = independent_variable.reshape(-1, 1)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(independent_variable, dependent_variable)\n",
    "\n",
    "# Predict the values using the model\n",
    "predicted_values = model.predict(independent_variable)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(dependent_variable, predicted_values)\n",
    "\n",
    "# Round the MSE to an integer\n",
    "rounded_mse = int(np.round(mse))\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Rounded Mean Squared Error:\", rounded_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a35dfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to convert array of bytes/strings into decimal numbers with dtype='numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3276\\2958940444.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Fit the model to the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindependent_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdependent_variable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Predict the values using the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    663\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    790\u001b[0m                     \u001b[1;34m\"Unable to convert array of bytes/strings \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                     \u001b[1;34m\"into decimal numbers with dtype='numeric'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to convert array of bytes/strings into decimal numbers with dtype='numeric'"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate or load your data\n",
    "independent_variable = np.array(['score'])  # Replace this with your actual independent variable data\n",
    "dependent_variable = np.array(['759'])  # Replace this with your actual dependent variable data\n",
    "\n",
    "# Reshape the independent variable to a 2D array if it's a single feature\n",
    "independent_variable = independent_variable.reshape(-1, 1)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(independent_variable, dependent_variable)\n",
    "\n",
    "# Predict the values using the model\n",
    "predicted_values = model.predict(independent_variable)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(dependent_variable, predicted_values)\n",
    "\n",
    "# Round the MSE to an integer\n",
    "rounded_mse = int(np.round(mse))\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Rounded Mean Squared Error:\", rounded_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a6f189",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3276\\4018218270.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Sample data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mindependent_variable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdependent_variable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'score'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Sample data\n",
    "independent_variable = np.array(['score'], dtype=float)\n",
    "dependent_variable = np.array(['2'], dtype=float)\n",
    "\n",
    "if independent_variable.shape != dependent_variable.shape:\n",
    "    raise ValueError(\"Data shape mismatch\")\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "try:\n",
    "    model.fit(independent_variable.reshape(-1, 1), dependent_variable)\n",
    "    predicted_values = model.predict(independent_variable.reshape(-1, 1))\n",
    "    mse = mean_squared_error(dependent_variable, predicted_values)\n",
    "    rounded_mse = int(np.round(mse))\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"Rounded Mean Squared Error:\", rounded_mse)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aeea4d43",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3276\\3503204631.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Define your features and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m767\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "# Define your features and labels\n",
    "X = df.iloc[:, 0:767]\n",
    "y = df['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e947451",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3276\\4215586885.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Train the model on the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mlogistic_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Make predictions on the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1506\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1508\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    977\u001b[0m     )\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[0;32m    992\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    112\u001b[0m         ):\n\u001b[0;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"infinity\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"NaN, infinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import filterwarnings\n",
    " \n",
    "# Assuming you have a dataset with features (X_train, X_test) and labels (y_train, y_test)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# Create a logistic regression model\n",
    "logistic_model = LogisticRegression(C=1.0, solver='lbfgs', max_iter=100)\n",
    " \n",
    "# Train the model on the training data\n",
    "logistic_model.fit(X_train, y_train)\n",
    " \n",
    "# Make predictions on the test data\n",
    "y_pred = logistic_model.predict(X_test)\n",
    " \n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    " \n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d460d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Load your data\n",
    "df = pd.read_csv(\"code_only.csv\")\n",
    "\n",
    "# Define features (X) and target values (y)\n",
    "X = df.drop(\"2\", axis=1)  # Adjust \"target_column\" to your target variable\n",
    "y = df[\"score\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfcbae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
